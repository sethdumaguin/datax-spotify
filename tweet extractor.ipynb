{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your username is: Yelloworiental3\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "# Ensure that Pandas shows at least 280 characters in columns, so we can see full tweets\n",
    "pd.set_option('max_colwidth', 280)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import re\n",
    "import tweepy\n",
    "\n",
    "\n",
    "import json\n",
    "key_file = 'keys.json'\n",
    "# Loading your keys from keys.json (which you should have filled\n",
    "# in in question 1):\n",
    "with open(key_file) as f:\n",
    "    keys = json.load(f)\n",
    "# if you print or view the contents of keys be sure to delete the cell!\n",
    "import tweepy\n",
    "from tweepy import TweepError\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    print(\"Your username is:\", api.auth.get_username())\n",
    "except TweepError as e:\n",
    "    logging.warning(\"There was a Tweepy error. Double check your API keys and try again.\")\n",
    "    logging.warning(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keys(path):\n",
    "    \"\"\"Loads your Twitter authentication keys from a file on disk.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The path to your key file.  The file should\n",
    "          be in JSON format and look like this (but filled in):\n",
    "            {\n",
    "                \"consumer_key\": \"<your Consumer Key here>\",\n",
    "                \"consumer_secret\":  \"<your Consumer Secret here>\",\n",
    "                \"access_token\": \"<your Access Token here>\",\n",
    "                \"access_token_secret\": \"<your Access Token Secret here>\"\n",
    "            }\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping key names (like \"consumer_key\") to\n",
    "          key values.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    with open(path) as f:\n",
    "        keys = json.load(f)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_recent_tweets_by_user(user_account_name, keys):\n",
    "    \"\"\"Downloads tweets by one Twitter user.\n",
    "\n",
    "    Args:\n",
    "        user_account_name (str): The name of the Twitter account\n",
    "          whose tweets will be downloaded.\n",
    "        keys (dict): A Python dictionary with Twitter authentication\n",
    "          keys (strings), like this (but filled in):\n",
    "            {\n",
    "                \"consumer_key\": \"<your Consumer Key here>\",\n",
    "                \"consumer_secret\":  \"<your Consumer Secret here>\",\n",
    "                \"access_token\": \"<your Access Token here>\",\n",
    "                \"access_token_secret\": \"<your Access Token Secret here>\"\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Dictonary objects, each representing one tweet.\"\"\"\n",
    "    import tweepy\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    example_tweets = [t._json for t in tweepy.Cursor(api.user_timeline, id=user_account_name, \n",
    "                                             tweet_mode='extended').items()]\n",
    "    return example_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets(tweets, path):\n",
    "    \"\"\"Saves a list of tweets to a file in the local filesystem.\n",
    "    \n",
    "    This function makes no guarantee about the format of the saved\n",
    "    tweets, **except** that calling load_tweets(path) after\n",
    "    save_tweets(tweets, path) will produce the same list of tweets\n",
    "    and that only the file at the given path is used to store the\n",
    "    tweets.  (That means you can implement this function however\n",
    "    you want, as long as saving and loading works!)\n",
    "\n",
    "    Args:\n",
    "        tweets (list): A list of tweet objects (of type Dictionary) to\n",
    "          be saved.\n",
    "        path (str): The place where the tweets will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(path):\n",
    "    \"\"\"Loads tweets that have previously been saved.\n",
    "    \n",
    "    Calling load_tweets(path) after save_tweets(tweets, path)\n",
    "    will produce the same list of tweets.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The place where the tweets were be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Dictionary objects, each representing one tweet.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    with open(path, \"r\") as f:\n",
    "        example_tweets = json.load(f)\n",
    "    return example_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_with_cache_obama(user_account_name, keys_path):\n",
    "    \"\"\"Get recent tweets from one user, loading from a disk cache if available.\n",
    "    \n",
    "    The first time you call this function, it will download tweets by\n",
    "    a user.  Subsequent calls will not re-download the tweets; instead\n",
    "    they'll load the tweets from a save file in your local filesystem.\n",
    "    All this is done using the functions you defined in the previous cell.\n",
    "    This has benefits and drawbacks that often appear when you cache data:\n",
    "    \n",
    "    +: Using this function will prevent extraneous usage of the Twitter API.\n",
    "    +: You will get your data much faster after the first time it's called.\n",
    "    -: If you really want to re-download the tweets (say, to get newer ones,\n",
    "       or because you screwed up something in the previous cell and your\n",
    "       tweets aren't what you wanted), you'll have to find the save file\n",
    "       (which will look like <something>_recent_tweets.pkl) and delete it.\n",
    "    \n",
    "    Args:\n",
    "        user_account_name (str): The Twitter handle of a user, without the @.\n",
    "        keys_path (str): The path to a JSON keys file in your filesystem.\n",
    "    \"\"\"\n",
    "    keys = load_keys(keys_path)\n",
    "    tweets_path = \"obamatweets.json\"\n",
    "    if not Path(tweets_path).is_file():\n",
    "        tweets = download_recent_tweets_by_user(user_account_name, keys)\n",
    "        save_tweets(tweets, tweets_path)\n",
    "    return load_tweets(tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets downloaded: 3210\n"
     ]
    }
   ],
   "source": [
    "obama_tweets = get_tweets_with_cache_obama(\"barackobama\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(obama_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_with_cache_embiid(user_account_name, keys_path):\n",
    "    \"\"\"Get recent tweets from one user, loading from a disk cache if available.\n",
    "    \n",
    "    The first time you call this function, it will download tweets by\n",
    "    a user.  Subsequent calls will not re-download the tweets; instead\n",
    "    they'll load the tweets from a save file in your local filesystem.\n",
    "    All this is done using the functions you defined in the previous cell.\n",
    "    This has benefits and drawbacks that often appear when you cache data:\n",
    "    \n",
    "    +: Using this function will prevent extraneous usage of the Twitter API.\n",
    "    +: You will get your data much faster after the first time it's called.\n",
    "    -: If you really want to re-download the tweets (say, to get newer ones,\n",
    "       or because you screwed up something in the previous cell and your\n",
    "       tweets aren't what you wanted), you'll have to find the save file\n",
    "       (which will look like <something>_recent_tweets.pkl) and delete it.\n",
    "    \n",
    "    Args:\n",
    "        user_account_name (str): The Twitter handle of a user, without the @.\n",
    "        keys_path (str): The path to a JSON keys file in your filesystem.\n",
    "    \"\"\"\n",
    "    keys = load_keys(keys_path)\n",
    "    tweets_path = \"embiid.json\"\n",
    "    if not Path(tweets_path).is_file():\n",
    "        tweets = download_recent_tweets_by_user(user_account_name, keys)\n",
    "        save_tweets(tweets, tweets_path)\n",
    "    return load_tweets(tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets downloaded: 2569\n"
     ]
    }
   ],
   "source": [
    "embiid_tweets = get_tweets_with_cache_embiid(\"JoelEmbiid\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(embiid_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_with_cache_ariana(user_account_name, keys_path):\n",
    "    \"\"\"Get recent tweets from one user, loading from a disk cache if available.\n",
    "    \n",
    "    The first time you call this function, it will download tweets by\n",
    "    a user.  Subsequent calls will not re-download the tweets; instead\n",
    "    they'll load the tweets from a save file in your local filesystem.\n",
    "    All this is done using the functions you defined in the previous cell.\n",
    "    This has benefits and drawbacks that often appear when you cache data:\n",
    "    \n",
    "    +: Using this function will prevent extraneous usage of the Twitter API.\n",
    "    +: You will get your data much faster after the first time it's called.\n",
    "    -: If you really want to re-download the tweets (say, to get newer ones,\n",
    "       or because you screwed up something in the previous cell and your\n",
    "       tweets aren't what you wanted), you'll have to find the save file\n",
    "       (which will look like <something>_recent_tweets.pkl) and delete it.\n",
    "    \n",
    "    Args:\n",
    "        user_account_name (str): The Twitter handle of a user, without the @.\n",
    "        keys_path (str): The path to a JSON keys file in your filesystem.\n",
    "    \"\"\"\n",
    "    keys = load_keys(keys_path)\n",
    "    tweets_path = \"ariana.json\"\n",
    "    if not Path(tweets_path).is_file():\n",
    "        tweets = download_recent_tweets_by_user(user_account_name, keys)\n",
    "        save_tweets(tweets, tweets_path)\n",
    "    return load_tweets(tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets downloaded: 3215\n"
     ]
    }
   ],
   "source": [
    "ariana_tweets = get_tweets_with_cache_ariana(\"arianagrande\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(ariana_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_with_cache_kehlani(user_account_name, keys_path):\n",
    "    \"\"\"Get recent tweets from one user, loading from a disk cache if available.\n",
    "    \n",
    "    The first time you call this function, it will download tweets by\n",
    "    a user.  Subsequent calls will not re-download the tweets; instead\n",
    "    they'll load the tweets from a save file in your local filesystem.\n",
    "    All this is done using the functions you defined in the previous cell.\n",
    "    This has benefits and drawbacks that often appear when you cache data:\n",
    "    \n",
    "    +: Using this function will prevent extraneous usage of the Twitter API.\n",
    "    +: You will get your data much faster after the first time it's called.\n",
    "    -: If you really want to re-download the tweets (say, to get newer ones,\n",
    "       or because you screwed up something in the previous cell and your\n",
    "       tweets aren't what you wanted), you'll have to find the save file\n",
    "       (which will look like <something>_recent_tweets.pkl) and delete it.\n",
    "    \n",
    "    Args:\n",
    "        user_account_name (str): The Twitter handle of a user, without the @.\n",
    "        keys_path (str): The path to a JSON keys file in your filesystem.\n",
    "    \"\"\"\n",
    "    keys = load_keys(keys_path)\n",
    "    tweets_path = \"kehlani.json\"\n",
    "    if not Path(tweets_path).is_file():\n",
    "        tweets = download_recent_tweets_by_user(user_account_name, keys)\n",
    "        save_tweets(tweets, tweets_path)\n",
    "    return load_tweets(tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets downloaded: 3215\n"
     ]
    }
   ],
   "source": [
    "kehlani_tweets = get_tweets_with_cache_ariana(\"kehlani\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(kehlani_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
