{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Code Below based off of Data 100 Project 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv('uncleanedds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "df = df[~df['full_text'].str.startswith('RT')]\n",
    "df = df[~df['full_text'].str.startswith('LIVE')]\n",
    "df = df[~df['full_text'].str.startswith('ICYMI')]\n",
    "df = df[~df['full_text'].str.startswith('WATCH')]\n",
    "df['no_punc_text'] = df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeatusernames(tweet):\n",
    "    return re.sub(r'(@[A-Za-z0-9]+)','',tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removelinks(tweet):\n",
    "    return re.sub(r'http\\S+','',tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removehashtags(tweet):\n",
    "    return re.sub(r'(#[A-Za-z0-9]+)','',tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeemojis(tweet):\n",
    "    return tweet.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePuncs(tweet):\n",
    "    return re.sub(r'[^\\w\\s]','', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(removelinks).apply(removeatusernames).apply(removehashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_punc_text'] = df['no_punc_text'].apply(removelinks).apply(removeatusernames).apply(removehashtags).apply(removePuncs).apply(removeemojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['no_punc_text'].str.startswith(' ')]\n",
    "df = df[~df['full_text'].str.startswith(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].str.lower()\n",
    "df['no_punc_text'] = df['no_punc_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = pd.read_csv('vader_lexicon.txt', delimiter=\"\\t\", names=['token', 'polarity', 'Col 3', 'Col 4']).loc[:, 'token':'polarity'].set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicate = sent.reset_index()\n",
    "no_duplicate = no_duplicate.drop_duplicates(subset='token', keep='first').set_index('token')\n",
    "r = sent.merge(tidy_format, how='inner', left_index=True, right_on='word')\n",
    "polarity_by_id = r.groupby(r.index)[['polarity']].sum()\n",
    "polarity = df.merge(polarity_by_id, how='outer', left_index=True, right_index=True).fillna(0)\n",
    "df['polarity'] = polarity['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment_analyzer_scores_1(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pol'] = df['full_text'].apply(sentiment_analyzer_scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>name</th>\n",
       "      <th>no_punc_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1113147225239040000</td>\n",
       "      <td>real protective wit my soul where u been</td>\n",
       "      <td>ariana</td>\n",
       "      <td>real protective wit my soul where u been</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113146485925744641</td>\n",
       "      <td>whatâ€™s your fav lyric ðŸŒªðŸŒ¬</td>\n",
       "      <td>ariana</td>\n",
       "      <td>whats your fav lyric</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1113140084637786113</td>\n",
       "      <td>we love u ðŸ–¤ thank u ðŸ–¤ !! ãƒ½( âŒ’oâŒ’)äºº(âŒ’â—‹âŒ’ )ï¾‰</td>\n",
       "      <td>ariana</td>\n",
       "      <td>we love u  thank u    o</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1113139911106813952</td>\n",
       "      <td>u deserve the world ! only up from here chicoo...</td>\n",
       "      <td>ariana</td>\n",
       "      <td>u deserve the world  only up from here chicooo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1112865178981416960</td>\n",
       "      <td>a full dad wrote this</td>\n",
       "      <td>ariana</td>\n",
       "      <td>a full dad wrote this</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1113147225239040000           real protective wit my soul where u been   \n",
       "1  1113146485925744641                        whatâ€™s your fav lyric ðŸŒªðŸŒ¬      \n",
       "3  1113140084637786113         we love u ðŸ–¤ thank u ðŸ–¤ !! ãƒ½( âŒ’oâŒ’)äºº(âŒ’â—‹âŒ’ )ï¾‰     \n",
       "4  1113139911106813952  u deserve the world ! only up from here chicoo...   \n",
       "8  1112865178981416960                             a full dad wrote this    \n",
       "\n",
       "     name                                       no_punc_text  polarity     pol  \n",
       "0  ariana           real protective wit my soul where u been       0.0  0.0000  \n",
       "1  ariana                           whats your fav lyric           4.4  0.4588  \n",
       "3  ariana                         we love u  thank u    o          4.7  0.8065  \n",
       "4  ariana  u deserve the world  only up from here chicooo...       0.0  0.0000  \n",
       "8  ariana                             a full dad wrote this        0.0  0.0000  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in df['no_punc_text']]\n",
    "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
    "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['sentiment'] = [1 if x >= 0 else 0 for x in sentiment_df['polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = sentiment_df[sentiment_df['polarity'] >= 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets = sentiment_df[sentiment_df['polarity'] < 0].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [positive_tweets[2200:4400],negative_tweets[300:600]]\n",
    "train = [positive_tweets[0:2200],negative_tweets[0:300]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = pd.concat(test)\n",
    "train_sent = pd.concat(train)\n",
    "alltogether = pd.concat([train_sent, test_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = alltogether.iloc[0:2500, 2].values\n",
    "y_train = alltogether.iloc[0:2500, 3].values\n",
    "X_test = alltogether.iloc[2500:, 2].values\n",
    "y_test = alltogether.iloc[2500:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "total_reviews = X_train + X_test\n",
    "tokenizer.fit_on_texts(total_reviews)\n",
    "max_length = max([len(s.split()) for s in total_reviews])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_length, padding = 'post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length = max_length))\n",
    "model.add(GRU(units = 32, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/25\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.5554 - acc: 0.8668 - val_loss: 0.4092 - val_acc: 0.8800\n",
      "Epoch 2/25\n",
      "2500/2500 [==============================] - 2s 986us/step - loss: 0.3792 - acc: 0.8800 - val_loss: 0.3724 - val_acc: 0.8800\n",
      "Epoch 3/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3700 - acc: 0.8800 - val_loss: 0.3683 - val_acc: 0.8800\n",
      "Epoch 4/25\n",
      "2500/2500 [==============================] - 2s 981us/step - loss: 0.3700 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 5/25\n",
      "2500/2500 [==============================] - 2s 982us/step - loss: 0.3688 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 6/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3683 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 7/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3682 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 8/25\n",
      "2500/2500 [==============================] - 2s 991us/step - loss: 0.3664 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 9/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3688 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 10/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3667 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 11/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3678 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 12/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3670 - acc: 0.8800 - val_loss: 0.3671 - val_acc: 0.8800\n",
      "Epoch 13/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3683 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 14/25\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3669 - acc: 0.8800 - val_loss: 0.3671 - val_acc: 0.8800\n",
      "Epoch 15/25\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3687 - acc: 0.8800 - val_loss: 0.3671 - val_acc: 0.8800\n",
      "Epoch 16/25\n",
      "2500/2500 [==============================] - 2s 986us/step - loss: 0.3702 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 17/25\n",
      "2500/2500 [==============================] - 2s 998us/step - loss: 0.3685 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 18/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3680 - acc: 0.8800 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 19/25\n",
      "2500/2500 [==============================] - 2s 988us/step - loss: 0.3673 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 20/25\n",
      "2500/2500 [==============================] - 2s 998us/step - loss: 0.3676 - acc: 0.8800 - val_loss: 0.3671 - val_acc: 0.8800\n",
      "Epoch 21/25\n",
      "2500/2500 [==============================] - 2s 983us/step - loss: 0.3678 - acc: 0.8800 - val_loss: 0.3672 - val_acc: 0.8800\n",
      "Epoch 22/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3683 - acc: 0.8800 - val_loss: 0.3672 - val_acc: 0.8800\n",
      "Epoch 23/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3689 - acc: 0.8800 - val_loss: 0.3674 - val_acc: 0.8800\n",
      "Epoch 24/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3692 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n",
      "Epoch 25/25\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3708 - acc: 0.8800 - val_loss: 0.3670 - val_acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5701dd68>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size = 128, epochs = 25, validation_data=(X_test_pad, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5877866 ],\n",
       "       [0.58541316]], dtype=float32)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsample1 = 'I dont know how to feel right now. I feel very hurt'\n",
    "testsample2 = 'this movie really sucks! can i get my money back please'\n",
    "tsts = [testsample1,testsample2]\n",
    "test_samples_tokens = tokenizer.texts_to_sequences(tsts)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen= max_length)\n",
    "model.predict(x = test_samples_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
