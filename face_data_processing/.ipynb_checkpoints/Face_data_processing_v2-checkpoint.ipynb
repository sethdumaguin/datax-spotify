{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MoodyLyrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML1</td>\n",
       "      <td>Usher</td>\n",
       "      <td>There Goes My Baby</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML2</td>\n",
       "      <td>Da'Ville</td>\n",
       "      <td>On My Mind</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML3</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>Rockstar 101</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML4</td>\n",
       "      <td>J. Holiday</td>\n",
       "      <td>Bed</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML5</td>\n",
       "      <td>Morgan Heritage</td>\n",
       "      <td>Don't Haffi Dread</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index           Artist               Title     Mood\n",
       "0   ML1            Usher  There Goes My Baby  relaxed\n",
       "1   ML2         Da'Ville          On My Mind  relaxed\n",
       "2   ML3          Rihanna       Rockstar 101   relaxed\n",
       "3   ML4       J. Holiday                 Bed  relaxed\n",
       "4   ML5  Morgan Heritage   Don't Haffi Dread    angry"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.read_csv('D:/Data-x data/MoodyLyrics/ml_balanced_v2.csv', sep = ';', header = 0);\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Spotify API data into the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_id = '6188e6e99ee3432e98f8fe2e01f19f3e'\n",
    "client_secret = 'f8b3bda411a14edf86be0513c6217e05'\n",
    "\n",
    "# Define a function that can find the uri #\n",
    "# Inspiration: https://nitratine.net/blog/post/finding-emotion-in-music-with-python/ #\n",
    "\n",
    "def find_uri(title, artist):\n",
    "    # Set up the credentials manager #\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    sp.trace=False\n",
    "    search_querry = title + ' ' + artist\n",
    "    result = sp.search(search_querry)\n",
    "    for i in result['tracks']['items']:\n",
    "        # Find a songh that matches title and artist\n",
    "        if (i['artists'][0]['name'] == artist) and (i['name'] == title):\n",
    "            return i['uri']\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                # Just take the first song returned by the search (might be named differently)\n",
    "                return result['tracks']['items'][0]['uri']\n",
    "            except:\n",
    "                # No results for artist and title\n",
    "                print (\"Cannot Find URI\")\n",
    "                return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2000\n",
      "100 / 2000\n",
      "200 / 2000\n",
      "300 / 2000\n",
      "400 / 2000\n",
      "500 / 2000\n",
      "600 / 2000\n",
      "700 / 2000\n",
      "800 / 2000\n",
      "900 / 2000\n",
      "1000 / 2000\n",
      "1100 / 2000\n",
      "1200 / 2000\n",
      "1300 / 2000\n",
      "1400 / 2000\n",
      "1500 / 2000\n",
      "1600 / 2000\n",
      "1700 / 2000\n",
      "1800 / 2000\n",
      "1900 / 2000\n"
     ]
    }
   ],
   "source": [
    "uri_list = []\n",
    "\n",
    "# Find all the uris #\n",
    "j = 0\n",
    "\n",
    "ml_len = ml_df.shape[0]\n",
    "\n",
    "for artist, song in zip(ml_df['Artist'], ml_df['Title']):\n",
    "    uri_list.append(find_uri(song, artist))\n",
    "    \n",
    "    if j % 100 == 0:\n",
    "        print('%s / %s' % (j, ml_len))\n",
    "    \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to get Spotify features #\n",
    "def find_feat(uri):\n",
    "    if uri == None:\n",
    "        feat_dict = {'bpm': np.nan,\n",
    "                     'nrgy': np.nan,\n",
    "                     'dnce': np.nan,\n",
    "                     'dB': np.nan,\n",
    "                     'live': np.nan,\n",
    "                     'val': np.nan,\n",
    "                     'dur': np.nan,\n",
    "                     'acous': np.nan,\n",
    "                     'spch': np.nan,\n",
    "                     'pop': np.nan}\n",
    "    else:\n",
    "        client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "        sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "        sp.trace=False\n",
    "        features = sp.audio_features(uri)\n",
    "    \n",
    "        feat_dict = {'bpm': features[0]['tempo'],\n",
    "                     'nrgy': features[0]['energy'],\n",
    "                     'dnce': features[0]['danceability'],\n",
    "                     'dB': features[0]['loudness'],\n",
    "                     'live': features[0]['liveness'],\n",
    "                     'val': features[0]['valence'],\n",
    "                     'dur': features[0]['duration_ms'],\n",
    "                     'acous': features[0]['acousticness'],\n",
    "                     'spch': features[0]['speechiness'],\n",
    "                     'pop': features[0]['instrumentalness']}\n",
    "        \n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2000\n",
      "100 / 2000\n",
      "200 / 2000\n",
      "300 / 2000\n",
      "400 / 2000\n",
      "500 / 2000\n",
      "600 / 2000\n",
      "700 / 2000\n",
      "800 / 2000\n",
      "900 / 2000\n",
      "1000 / 2000\n",
      "1100 / 2000\n",
      "1200 / 2000\n",
      "1300 / 2000\n",
      "1400 / 2000\n",
      "1500 / 2000\n",
      "1600 / 2000\n",
      "1700 / 2000\n",
      "1800 / 2000\n",
      "1900 / 2000\n"
     ]
    }
   ],
   "source": [
    "# Use song uri's to find spotify data #\n",
    "\n",
    "# Create empty lists #\n",
    "feat = {'bpm': [], 'nrgy': [], 'dnce': [],\n",
    "        'dB': [], 'live': [], 'val': [],\n",
    "        'dur': [], 'acous': [], 'spch': [],\n",
    "        'pop': []}\n",
    "\n",
    "k = 0\n",
    "\n",
    "for uri in uri_list:\n",
    "    feats = find_feat(uri)\n",
    "    # Append #\n",
    "    feat['bpm'].append(feats['bpm'])\n",
    "    feat['nrgy'].append(feats['nrgy'])\n",
    "    feat['dnce'].append(feats['dnce'])\n",
    "    feat['dB'].append(feats['dB'])\n",
    "    feat['live'].append(feats['live'])\n",
    "    feat['val'].append(feats['val'])\n",
    "    feat['dur'].append(feats['dur'])\n",
    "    feat['acous'].append(feats['acous'])\n",
    "    feat['spch'].append(feats['spch'])\n",
    "    feat['pop'].append(feats['pop'])\n",
    "    \n",
    "    if k % 100 == 0:\n",
    "        print('%s / %s' % (k, len(uri_list)))\n",
    "    \n",
    "    k += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_df['uri'] = uri_list\n",
    "ml_df['bpm'] = feat['bpm']\n",
    "ml_df['nrgy'] = feat['nrgy']\n",
    "ml_df['dnce'] = feat['dnce']\n",
    "ml_df['dB'] = feat['dB']\n",
    "ml_df['live'] = feat['live']\n",
    "ml_df['val'] = feat['val']\n",
    "#ml_df['val'] = ml_df['val']*100\n",
    "ml_df['dur'] = feat['dur']\n",
    "ml_df['acous'] = feat['acous']\n",
    "ml_df['spch'] = feat['spch']\n",
    "ml_df['pop'] = feat['pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataframe for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index     0\n",
       "Artist    0\n",
       "Title     0\n",
       "Mood      0\n",
       "uri       0\n",
       "bpm       0\n",
       "nrgy      0\n",
       "dnce      0\n",
       "dB        0\n",
       "live      0\n",
       "val       0\n",
       "dur       0\n",
       "acous     0\n",
       "spch      0\n",
       "pop       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = ml_df.dropna(axis = 0)\n",
    "\n",
    "ml_df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Mood</th>\n",
       "      <th>uri</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>acous</th>\n",
       "      <th>spch</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML1</td>\n",
       "      <td>Usher</td>\n",
       "      <td>There Goes My Baby</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>spotify:track:6IUiqtI8tE49sqGbmtrNd8</td>\n",
       "      <td>77.468</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.257</td>\n",
       "      <td>281293.0</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML2</td>\n",
       "      <td>Da'Ville</td>\n",
       "      <td>On My Mind</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>spotify:track:3ZTHqAgrKgfS1NSZEdM9Io</td>\n",
       "      <td>167.852</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.628</td>\n",
       "      <td>-6.958</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.807</td>\n",
       "      <td>203373.0</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML3</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>Rockstar 101</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>spotify:track:5rXDTihGQ3TkYE3pmraAmH</td>\n",
       "      <td>170.697</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-4.624</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.315</td>\n",
       "      <td>238893.0</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML4</td>\n",
       "      <td>J. Holiday</td>\n",
       "      <td>Bed</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>spotify:track:6TlRNJaezOdzdECnQeRuMM</td>\n",
       "      <td>127.901</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-7.268</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.723</td>\n",
       "      <td>275107.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML5</td>\n",
       "      <td>Morgan Heritage</td>\n",
       "      <td>Don't Haffi Dread</td>\n",
       "      <td>angry</td>\n",
       "      <td>spotify:track:5HdF2l0OkkRfpjac0NEoJR</td>\n",
       "      <td>140.930</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.621</td>\n",
       "      <td>-6.365</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.829</td>\n",
       "      <td>496160.0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index           Artist               Title     Mood  \\\n",
       "0   ML1            Usher  There Goes My Baby  relaxed   \n",
       "1   ML2         Da'Ville          On My Mind  relaxed   \n",
       "2   ML3          Rihanna       Rockstar 101   relaxed   \n",
       "3   ML4       J. Holiday                 Bed  relaxed   \n",
       "4   ML5  Morgan Heritage   Don't Haffi Dread    angry   \n",
       "\n",
       "                                    uri      bpm   nrgy   dnce     dB   live  \\\n",
       "0  spotify:track:6IUiqtI8tE49sqGbmtrNd8   77.468  0.520  0.626 -8.077  0.130   \n",
       "1  spotify:track:3ZTHqAgrKgfS1NSZEdM9Io  167.852  0.574  0.628 -6.958  0.066   \n",
       "2  spotify:track:5rXDTihGQ3TkYE3pmraAmH  170.697  0.650  0.343 -4.624  0.646   \n",
       "3  spotify:track:6TlRNJaezOdzdECnQeRuMM  127.901  0.606  0.684 -7.268  0.058   \n",
       "4  spotify:track:5HdF2l0OkkRfpjac0NEoJR  140.930  0.733  0.621 -6.365  0.452   \n",
       "\n",
       "     val       dur   acous    spch       pop  \n",
       "0  0.257  281293.0  0.1750  0.0892  0.000000  \n",
       "1  0.807  203373.0  0.0308  0.0550  0.000011  \n",
       "2  0.315  238893.0  0.0299  0.0909  0.000000  \n",
       "3  0.723  275107.0  0.1700  0.0504  0.000000  \n",
       "4  0.829  496160.0  0.0326  0.0537  0.000000  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_df.to_csv('D:/Data-x data/ml_mod_v1.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for model-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(ml_df.loc[:, ['bpm', 'nrgy', 'dnce', 'dB', 'live', 'val', 'dur', 'acous', 'spch']])\n",
    "Y = ml_df['Mood']\n",
    "\n",
    "labelEncoder=LabelEncoder()\n",
    "y = labelEncoder.fit_transform(Y)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "# y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build random forest #\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(min_samples_leaf = 5, random_state = 0, n_estimators = 1000,\n",
    "                            criterion = 'gini', max_features = None, n_jobs = -1, oob_score = True)\n",
    "rf_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 40.77%\n",
      "Precision = [0.46721311 0.34259259 0.42156863 0.37931034]\n",
      "Recall = [0.64772727 0.38947368 0.40566038 0.21782178]\n",
      "F1 score = [0.54285714 0.36453202 0.41346154 0.27672956]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_v2 = labelEncoder.inverse_transform(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy = %.2f%%' % (accuracy_score(y_true = Y_test, y_pred = y_pred)*100))\n",
    "print('Precision =', precision_score(y_true = Y_test, y_pred = y_pred, average = None))\n",
    "print('Recall =', recall_score(y_true = Y_test, y_pred = y_pred, average = None))\n",
    "print('F1 score =', f1_score(y_true = Y_test, y_pred = y_pred, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build neural network\n",
    "# inp = Input(name='inputs', shape = X_train.shape)\n",
    "# x = LSTM(32)(inp)\n",
    "# x = Dense(256, name='FC1')(inp)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(4,name='out_layer')(x)\n",
    "# out = Activation('softmax')(x)\n",
    "# model = Model(inputs = inp, outputs=out)\n",
    "# \n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(), metrics=['accuracy'])\n",
    "# history=model.fit(X_train, Y_train, batch_size=128, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load old data with lyrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>added</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>acous</th>\n",
       "      <th>spch</th>\n",
       "      <th>pop</th>\n",
       "      <th>title_core</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyric_pos_sent</th>\n",
       "      <th>lyric_neg_sent</th>\n",
       "      <th>Pos/Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's You - Radio Edit</td>\n",
       "      <td>Syn Cole</td>\n",
       "      <td>big room</td>\n",
       "      <td>2015</td>\n",
       "      <td>2017‑10‑07</td>\n",
       "      <td>128</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>-4</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>212</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>It's You</td>\n",
       "      <td>[Verse 1: Syn Cole]\\r\\nPaints like a picture, ...</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Show You Love</td>\n",
       "      <td>Kato</td>\n",
       "      <td>danish hip hop</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018‑10‑25</td>\n",
       "      <td>124</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>183</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>Show You Love</td>\n",
       "      <td>[Verse 1: Hailee Steinfeld]\\r\\nI'll do this th...</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just Us</td>\n",
       "      <td>Said the Sky</td>\n",
       "      <td>chillstep</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019‑02‑28</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>-5</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>163</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>Just Us</td>\n",
       "      <td>[Verse 1]\\r\\nBeen so long\\r\\nSince I had someo...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warriors - Rob Adans Remix</td>\n",
       "      <td>Nicky Romero</td>\n",
       "      <td>big room</td>\n",
       "      <td>2015</td>\n",
       "      <td>2017‑05‑17</td>\n",
       "      <td>127</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>-3</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>[Verse]\\r\\nEmerging from the dust and rubble\\r...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Sweet Escape</td>\n",
       "      <td>Gwen Stefani</td>\n",
       "      <td>australian pop</td>\n",
       "      <td>2006</td>\n",
       "      <td>2016‑01‑08</td>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>-3</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>246</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>The Sweet Escape</td>\n",
       "      <td>[Intro: Akon]\\r\\nKonvict, Konvict, Konvict\\r\\n...</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title        artist       top genre  year       added  \\\n",
       "0       It's You - Radio Edit      Syn Cole        big room  2015  2017‑10‑07   \n",
       "1               Show You Love          Kato  danish hip hop  2017  2018‑10‑25   \n",
       "2                     Just Us  Said the Sky       chillstep  2018  2019‑02‑28   \n",
       "3  Warriors - Rob Adans Remix  Nicky Romero        big room  2015  2017‑05‑17   \n",
       "4            The Sweet Escape  Gwen Stefani  australian pop  2006  2016‑01‑08   \n",
       "\n",
       "   bpm  nrgy  dnce  dB  live  val  dur  acous  spch  pop        title_core  \\\n",
       "0  128    83    65  -4    13   49  212     11     5   58          It's You   \n",
       "1  124    83    69  -5     7   66  183     29     7   47     Show You Love   \n",
       "2  109    58    75  -5    10   33  163     19     6   68           Just Us   \n",
       "3  127    89    67  -3    66   65  312      0     4   36          Warriors   \n",
       "4  120    77    75  -3    16   74  246     21     3   66  The Sweet Escape   \n",
       "\n",
       "                                              lyrics  lyric_pos_sent  \\\n",
       "0  [Verse 1: Syn Cole]\\r\\nPaints like a picture, ...           0.191   \n",
       "1  [Verse 1: Hailee Steinfeld]\\r\\nI'll do this th...           0.363   \n",
       "2  [Verse 1]\\r\\nBeen so long\\r\\nSince I had someo...           0.050   \n",
       "3  [Verse]\\r\\nEmerging from the dust and rubble\\r...           0.000   \n",
       "4  [Intro: Akon]\\r\\nKonvict, Konvict, Konvict\\r\\n...           0.123   \n",
       "\n",
       "   lyric_neg_sent  Pos/Neg  \n",
       "0           0.100        1  \n",
       "1           0.025        1  \n",
       "2           0.041        1  \n",
       "3           0.111        0  \n",
       "4           0.127        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyr = pd.read_csv('D:/Data-x data/Spotify_v3.csv', sep = ';', index_col = 0)\n",
    "df_lyr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** <br>\n",
    "The variables that are used in the before made Random forest model is:\n",
    "- bpm: [Min = 49, Max = 204]\n",
    "- nrgy: [Min = 0, Max = 99]\n",
    "- dnce: [Min = 7, Max = 97]\n",
    "- dB: [Min = -36, Max = -1]\n",
    "- live: [Min = 2, Max = 97]\n",
    "- val: [Min = 3, Max = 97]\n",
    "- dur: [Min = 58, Max = 695]\n",
    "- acous: [Min = 0, Max = 100]\n",
    "- spch: [Min = 2, Max = 62]\n",
    "- pop: [Min = 0, Max = 98] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load facial images data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import os\n",
    "from os import walk\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation,Flatten\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rlangergaard/Notebooks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face = pd.read_csv('/home/rlangergaard/fer2013_(1).csv', sep = ',')\n",
    "df_face.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_train = df_face.loc[df_face['Usage'] == 'Training']\n",
    "df_face_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_test = df_face.loc[df_face['Usage'] != 'Training']\n",
    "df_face_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = df_face_train['pixels']\n",
    "Y_train = df_face_train['emotion']\n",
    "\n",
    "# Test data\n",
    "X_test = df_face_test['pixels']\n",
    "Y_test = df_face_test['emotion']\n",
    "X_test.index = range(0, len(X_test))\n",
    "Y_test.index = range(0, len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preparation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_matrix(imagePath):\n",
    "    image=cv2.imread(imagePath)\n",
    "    image=cv2.resize(image, (48,48))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    labels = []\n",
    "    for (_, dirnames, _) in walk(path):\n",
    "        labels.extend(dirnames)\n",
    "    for label in labels:\n",
    "        for root, dirs, files in os.walk(os.path.abspath(path+'/'+label)):\n",
    "            for file in files:\n",
    "                imagePath=root +'/'+ file\n",
    "                image=img_to_matrix(imagePath)\n",
    "                X.append(image)\n",
    "                Y.append([int(label)])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X,Y):\n",
    "    flat_X = np.array(X)\n",
    "    flat_Y = np.array(Y)\n",
    "    flat_X = flat_X.astype('float32')\n",
    "    flat_X/=255\n",
    "    flat_Y = keras.utils.to_categorical(flat_Y, num_classes)\n",
    "    return flat_X,flat_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_pix_to_arr(X):\n",
    "    arr = np.array(list(map(int, X[0].split(' '))))\n",
    "    arr = arr.astype('float32')\n",
    "    arr /= 255\n",
    "    arr = arr.reshape(-1, 48, 48, 1)\n",
    "    for i in range(1, len(X)):\n",
    "        tmp = np.array(list(map(int, X[i].split(' '))))\n",
    "        tmp = tmp.astype('float32')\n",
    "        tmp /= 255\n",
    "        tmp = tmp.reshape(-1, 48, 48, 1)\n",
    "    \n",
    "        arr = np.append(arr, tmp, axis = 0)\n",
    "        \n",
    "        if (i / len(X)) % 0.1 == 0:\n",
    "            print('Progress = %s%%' % ((i / len(X))*100))\n",
    "        \n",
    "    print(arr.shape)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Y_to_cat(Y, num_classes):\n",
    "    Y_tmp = np.array(Y)\n",
    "    Y_tmp = keras.utils.to_categorical(Y_tmp, num_classes)\n",
    "    \n",
    "    print(Y_tmp.shape)\n",
    "    \n",
    "    return Y_tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(7178, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = str_pix_to_arr(X_train)\n",
    "X_test = str_pix_to_arr(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training input = (28709, 48, 48, 1)\n",
      "Shape of test input = (7178, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training input =', X_train.shape)\n",
    "print('Shape of test input =', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 7)\n",
      "(7178, 7)\n"
     ]
    }
   ],
   "source": [
    "Y_train = Y_to_cat(Y_train, len(set(Y_train)))\n",
    "Y_test = Y_to_cat(Y_test, len(set(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN with to predict mood from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes = 7\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(Y_train[0])\n",
    "print('Number of classes =', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 3,823,367\n",
      "Trainable params: 3,819,399\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################### Build the neural network ##################\n",
    "\n",
    "# Inspiration https://github.com/achyuta26/MusicalFace/blob/master/train_cnn_face.py #\n",
    "\n",
    "face_CNN = Sequential()\n",
    "\n",
    "#1st block\n",
    "face_CNN.add(Conv2D(64, (3,3), strides = (1,1), padding='same',\n",
    "                 input_shape = X_train.shape[1:],\n",
    "                   kernel_initializer=\"lecun_uniform\",\n",
    "                   kernel_regularizer=regularizers.l2(0)))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('tanh'))\n",
    "face_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_CNN.add(Dropout(0.25))\n",
    "\n",
    "#2nd block\n",
    "face_CNN.add(Conv2D(128, (5,5), strides = (1,1),kernel_regularizer=regularizers.l2(0)))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('tanh'))\n",
    "face_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_CNN.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#3rd block\n",
    "face_CNN.add(Conv2D(512, (3,3), strides = (1,1), padding='same',kernel_regularizer=regularizers.l2(0)))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('tanh'))\n",
    "face_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_CNN.add(Dropout(0.5))\n",
    "\n",
    "#4th block\n",
    "face_CNN.add(Conv2D(512, (3,3), strides = (1,1), padding='same',kernel_regularizer=regularizers.l2(0)))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('tanh'))\n",
    "face_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_CNN.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "#5th block\n",
    "face_CNN.add(Flatten())\n",
    "face_CNN.add(Dense(256,kernel_initializer=\"lecun_uniform\"))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('relu'))\n",
    "face_CNN.add(Dropout(0.5))\n",
    "face_CNN.add(Dense(512,kernel_initializer=\"lecun_uniform\"))\n",
    "face_CNN.add(BatchNormalization())\n",
    "face_CNN.add(Activation('relu'))\n",
    "face_CNN.add(Dropout(0.5))\n",
    "face_CNN.add(Dense(num_classes))\n",
    "face_CNN.add(Activation('softmax'))\n",
    "\n",
    "face_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "\n",
    "face_CNN.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=7, \\\n",
    "                          verbose=1, mode='auto')\n",
    "history = History()\n",
    "callbacks = [earlystop, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/35\n",
      "28709/28709 [==============================] - 481s 17ms/step - loss: 1.9119 - acc: 0.2680 - val_loss: 1.6394 - val_acc: 0.3520\n",
      "Epoch 2/35\n",
      "28709/28709 [==============================] - 475s 17ms/step - loss: 1.5642 - acc: 0.3923 - val_loss: 1.4840 - val_acc: 0.4334\n",
      "Epoch 3/35\n",
      "28709/28709 [==============================] - 477s 17ms/step - loss: 1.4164 - acc: 0.4548 - val_loss: 1.3392 - val_acc: 0.4844\n",
      "Epoch 4/35\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 1.3306 - acc: 0.4946 - val_loss: 1.2697 - val_acc: 0.5033\n",
      "Epoch 5/35\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 1.2757 - acc: 0.5130 - val_loss: 1.2614 - val_acc: 0.5188\n",
      "Epoch 6/35\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 1.2304 - acc: 0.5343 - val_loss: 1.1867 - val_acc: 0.5475\n",
      "Epoch 7/35\n",
      "28709/28709 [==============================] - 478s 17ms/step - loss: 1.1826 - acc: 0.5545 - val_loss: 1.1586 - val_acc: 0.5639\n",
      "Epoch 8/35\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 1.1522 - acc: 0.5643 - val_loss: 1.1655 - val_acc: 0.5581\n",
      "Epoch 9/35\n",
      "28709/28709 [==============================] - 478s 17ms/step - loss: 1.1066 - acc: 0.5852 - val_loss: 1.1352 - val_acc: 0.5711\n",
      "Epoch 10/35\n",
      "28709/28709 [==============================] - 475s 17ms/step - loss: 1.0764 - acc: 0.5939 - val_loss: 1.1440 - val_acc: 0.5673\n",
      "Epoch 11/35\n",
      "28709/28709 [==============================] - 476s 17ms/step - loss: 1.0394 - acc: 0.6089 - val_loss: 1.1321 - val_acc: 0.5736\n",
      "Epoch 12/35\n",
      "28709/28709 [==============================] - 484s 17ms/step - loss: 1.0130 - acc: 0.6195 - val_loss: 1.0851 - val_acc: 0.5875\n",
      "Epoch 13/35\n",
      "28709/28709 [==============================] - 476s 17ms/step - loss: 0.9703 - acc: 0.6368 - val_loss: 1.0824 - val_acc: 0.6003\n",
      "Epoch 14/35\n",
      "28709/28709 [==============================] - 477s 17ms/step - loss: 0.9336 - acc: 0.6491 - val_loss: 1.0971 - val_acc: 0.5918\n",
      "Epoch 15/35\n",
      "28709/28709 [==============================] - 475s 17ms/step - loss: 0.9010 - acc: 0.6644 - val_loss: 1.0835 - val_acc: 0.6000\n",
      "Epoch 16/35\n",
      "28709/28709 [==============================] - 476s 17ms/step - loss: 0.8685 - acc: 0.6769 - val_loss: 1.1083 - val_acc: 0.5945\n",
      "Epoch 17/35\n",
      "28709/28709 [==============================] - 481s 17ms/step - loss: 0.8390 - acc: 0.6865 - val_loss: 1.0659 - val_acc: 0.6151\n",
      "Epoch 18/35\n",
      "28709/28709 [==============================] - 490s 17ms/step - loss: 0.8091 - acc: 0.7021 - val_loss: 1.1224 - val_acc: 0.5954\n",
      "Epoch 19/35\n",
      "28709/28709 [==============================] - 495s 17ms/step - loss: 0.7773 - acc: 0.7126 - val_loss: 1.0891 - val_acc: 0.6112\n",
      "Epoch 20/35\n",
      "28709/28709 [==============================] - 497s 17ms/step - loss: 0.7498 - acc: 0.7229 - val_loss: 1.1099 - val_acc: 0.5979\n",
      "Epoch 21/35\n",
      "28709/28709 [==============================] - 497s 17ms/step - loss: 0.7218 - acc: 0.7351 - val_loss: 1.1403 - val_acc: 0.6082\n",
      "Epoch 22/35\n",
      "28709/28709 [==============================] - 495s 17ms/step - loss: 0.6930 - acc: 0.7428 - val_loss: 1.1208 - val_acc: 0.6130\n",
      "Epoch 23/35\n",
      "28709/28709 [==============================] - 492s 17ms/step - loss: 0.6723 - acc: 0.7492 - val_loss: 1.1338 - val_acc: 0.6147\n",
      "Epoch 24/35\n",
      "28709/28709 [==============================] - 490s 17ms/step - loss: 0.6479 - acc: 0.7622 - val_loss: 1.1183 - val_acc: 0.6159\n",
      "Epoch 25/35\n",
      "28709/28709 [==============================] - 490s 17ms/step - loss: 0.6183 - acc: 0.7716 - val_loss: 1.1505 - val_acc: 0.6172\n",
      "Epoch 26/35\n",
      "28709/28709 [==============================] - 495s 17ms/step - loss: 0.5979 - acc: 0.7823 - val_loss: 1.2087 - val_acc: 0.6066\n",
      "Epoch 27/35\n",
      "28709/28709 [==============================] - 497s 17ms/step - loss: 0.5779 - acc: 0.7887 - val_loss: 1.1780 - val_acc: 0.6188\n",
      "Epoch 28/35\n",
      "28709/28709 [==============================] - 480s 17ms/step - loss: 0.5650 - acc: 0.7947 - val_loss: 1.1658 - val_acc: 0.6190\n",
      "Epoch 29/35\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 0.5358 - acc: 0.8095 - val_loss: 1.2041 - val_acc: 0.6159\n",
      "Epoch 30/35\n",
      "28709/28709 [==============================] - 475s 17ms/step - loss: 0.5202 - acc: 0.8105 - val_loss: 1.2286 - val_acc: 0.6230\n",
      "Epoch 31/35\n",
      "28709/28709 [==============================] - 476s 17ms/step - loss: 0.5094 - acc: 0.8137 - val_loss: 1.2096 - val_acc: 0.6243\n",
      "Epoch 32/35\n",
      "28709/28709 [==============================] - 489s 17ms/step - loss: 0.4891 - acc: 0.8235 - val_loss: 1.2496 - val_acc: 0.6234\n",
      "Epoch 33/35\n",
      "28709/28709 [==============================] - 493s 17ms/step - loss: 0.4705 - acc: 0.8322 - val_loss: 1.2638 - val_acc: 0.6229\n",
      "Epoch 34/35\n",
      "28709/28709 [==============================] - 498s 17ms/step - loss: 0.4646 - acc: 0.8312 - val_loss: 1.2810 - val_acc: 0.6159\n",
      "Epoch 35/35\n",
      "28709/28709 [==============================] - 522s 18ms/step - loss: 0.4490 - acc: 0.8395 - val_loss: 1.2929 - val_acc: 0.6211\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 35\n",
    "\n",
    "hist_CNN = face_CNN.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlangergaard/ENTER/lib/python3.5/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "\n",
    "# Training accuracy\n",
    "plt.subplot(221)\n",
    "plt.plot(range(0,35), history.history['acc'], c = 'forestgreen');\n",
    "plt.title('Training accuracy per epoch');\n",
    "\n",
    "# Training loss #\n",
    "plt.subplot(222)\n",
    "plt.plot(range(0,35), history.history['loss'], c = 'forestgreen');\n",
    "plt.title('Training loss per epoch');\n",
    "\n",
    "# Validation accuracy #\n",
    "plt.subplot(223)\n",
    "plt.plot(range(0,35), history.history['val_acc'], c = 'blue');\n",
    "plt.title('Validation accuracy per epoch');\n",
    "\n",
    "# Validation loss #\n",
    "plt.subplot(224)\n",
    "plt.plot(range(0,35), history.history['val_loss'], c = 'blue');\n",
    "plt.title('Validation loss per epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy = 62.10643633324045%\n"
     ]
    }
   ],
   "source": [
    "print(\"Final test accuracy = %s%%\" % (history.history['val_acc'][-1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_CNN.save('face_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('face_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-aa25efff83b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_model = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = dill.load(open('face_CNN.pickle', 'rb'))\n",
    "\n",
    "y_pred_pickle = mod.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prediction from saved model = [0.34562925 0.00704463 0.11611738 0.0027287  0.38321576 0.00087468\n",
      " 0.14438967]\n",
      "First prediction from pickle model = [0.34562925 0.00704463 0.11611738 0.0027287  0.38321576 0.00087468\n",
      " 0.14438967]\n"
     ]
    }
   ],
   "source": [
    "print('First prediction from saved model =', y_pred_model[0])\n",
    "print('First prediction from pickle model =', y_pred_pickle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7178, 7)\n",
      "(7178,)\n",
      "[4 1 0 4 3 3 4 4 3 2]\n"
     ]
    }
   ],
   "source": [
    "a = y_pred_model\n",
    "print(a.shape)\n",
    "a_new = a.argmax(axis = 1)\n",
    "print(a_new.shape)\n",
    "print(a_new[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import tempfile\n",
    "import keras.models\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import pickle\n",
    "\n",
    "make_keras_picklable()\n",
    "\n",
    "pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This works like a charm http://zachmoshe.com/2017/04/03/pickling-keras-models.html:\n",
    "\n",
    "import types\n",
    "import tempfile\n",
    "import keras.models\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__\n",
    "\n",
    "make_keras_picklable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "filename = 'face_CNN.pickle'\n",
    "\n",
    "pickle_out = open(filename, 'wb')\n",
    "\n",
    "dill.dump(model, pickle_out)\n",
    "\n",
    "#dill.dumps(model, pickle_out)\n",
    "\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn CNN predictions into the same predictions as MoodyLyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mood in the fer2013 facial image data is labeled as follows:\n",
    "\n",
    "| Mood | Code  |\n",
    "| --- | --- |\n",
    "| Angry | 0 |\n",
    "| Disgust | 1 |\n",
    "| Fear | 2 |\n",
    "| Happy | 3 |\n",
    "| Sad | 4 |\n",
    "| Surprised | 5 |\n",
    "| Neutral | 6 |\n",
    "\n",
    "Where the MoodyLyrics dataset only have the following four categories:\n",
    "\n",
    "| Mood | Code  |\n",
    "| --- | --- |\n",
    "| Happy | 0 |\n",
    "| Angry | 1 |\n",
    "| Sad | 2 |\n",
    "| Relaxed | 3 |\n",
    "\n",
    "\n",
    "To combine the two datasets the following generalization will be made:\n",
    "\n",
    "| Fer2013 Mood | MoodyLyrics mood |\n",
    "| --- | --- |\n",
    "| Happy | Happy |\n",
    "| Fear, Sad | Sad |\n",
    "| Angry, disgust | Angry |\n",
    "| Surprised, Neutral | Relaxed |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def face_to_moodlyr(y_pred):\n",
    "    new_pred = []\n",
    "    for pred in y_pred:\n",
    "        if pred == 3:\n",
    "            new_pred.append(0)\n",
    "        elif pred == 0 or pred == 1:\n",
    "            new_pred.append(1)\n",
    "        elif pred == 2 or pred == 4:\n",
    "            new_pred.append(2)\n",
    "        else:\n",
    "            new_pred.append(3)\n",
    "    return np.array(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ml_pred array: (7178,)\n",
      "Predictions in ml_pred: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "ml_pred = face_to_moodlyr(a_new)\n",
    "print('Shape of ml_pred array:', ml_pred.shape)\n",
    "\n",
    "print('Predictions in ml_pred:', set(ml_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
